{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Thompson Sampling model\n",
    "Here is a simple example of using Reinforcement Learning through the Thompson Sampling model. We aim to build a model that helps us identify, among five slot machines gaming, the one that offers us the highest probability of winning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importing the libraries\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Setting conversion rates and the number of samples\n",
    "conversionRates = [0.15, 0.04, 0.13, 0.11, 0.05]\n",
    "N = 10000 # is the number of attempts \n",
    "d = len(conversionRates) # is the number of slot machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset.\n",
    "X = np.zeros((N, d))\n",
    "for i in range(N):\n",
    "    for j in range(d):\n",
    "        # if the random float is smaller, then that means you will win if you play this certain machine at this certain timestep.\n",
    "        if np.random.rand() < conversionRates[j]:\n",
    "            X[i][j] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making arrays to count our losses and wins\n",
    "nPosReward = np.zeros(d)\n",
    "nNegReward = np.zeros(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thompson Sampling uses a distribution function (distributions will be explained further in this chapter), called Beta, that takes two arguments. For simplicity's sake, let's say that the higher the first argument is, the better our slot machine is, and the higher the second argument is, the worse our slot machine is.\n",
    "\n",
    "$x = {\\beta(a, b)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking our best slot machine through beta distribution and updating its losses and wins\n",
    "for i in range(N):\n",
    "    selected = 0\n",
    "    maxRandom = 0\n",
    "\n",
    "    for j in range(d):\n",
    "        randomBeta = np.random.beta(nPosReward[j] + 1, nNegReward[j] + 1)\n",
    "        if randomBeta > maxRandom:\n",
    "            maxRandom = randomBeta\n",
    "            selected = j\n",
    "\n",
    "    if X[i][selected] == 1:\n",
    "        nPosReward[selected] += 1\n",
    "    else:\n",
    "        nNegReward[selected] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine number 1 was selected 8646.0 times\n",
      "Machine number 2 was selected 61.0 times\n",
      "Machine number 3 was selected 942.0 times\n",
      "Machine number 4 was selected 289.0 times\n",
      "Machine number 5 was selected 62.0 times\n",
      "Conclusion: Best machine is machine number 1\n"
     ]
    }
   ],
   "source": [
    "# Showing which slot machine is considered the best\n",
    "nSelected = nPosReward + nNegReward \n",
    "for i in range(d):\n",
    "    print('Machine number ' + str(i + 1) + ' was selected ' + str(nSelected[i]) + ' times')\n",
    "print('Conclusion: Best machine is machine number ' + str(np.argmax(nSelected) + 1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
